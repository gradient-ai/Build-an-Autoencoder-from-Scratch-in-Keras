{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to Build a Variational Autoencoder in Keras\n",
    "For a detailed tutorial, check out the post [on the blog](https://blog.paperspace.com/how-to-build-variational-autoencoder-keras/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aCshAL5ZlnvE"
   },
   "source": [
    "## Building the Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 850
    },
    "colab_type": "code",
    "gradient": {},
    "id": "M2RVB2Vvj3y3",
    "outputId": "2a0b1722-8825-4f6c-84b3-d78e758d4e5d"
   },
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "import numpy\n",
    "import matplotlib.pyplot\n",
    "\n",
    "img_size = 28\n",
    "num_channels = 1\n",
    "latent_space_dim = 2\n",
    "\n",
    "# Encoder\n",
    "x = tensorflow.keras.layers.Input(shape=(img_size, img_size, num_channels), name=\"encoder_input\")\n",
    "\n",
    "encoder_conv_layer1 = tensorflow.keras.layers.Conv2D(filters=1, kernel_size=(3, 3), padding=\"same\", strides=1, name=\"encoder_conv_1\")(x)\n",
    "encoder_norm_layer1 = tensorflow.keras.layers.BatchNormalization(name=\"encoder_norm_1\")(encoder_conv_layer1)\n",
    "encoder_activ_layer1 = tensorflow.keras.layers.LeakyReLU(name=\"encoder_leakyrelu_1\")(encoder_norm_layer1)\n",
    "\n",
    "encoder_conv_layer2 = tensorflow.keras.layers.Conv2D(filters=32, kernel_size=(3,3), padding=\"same\", strides=1, name=\"encoder_conv_2\")(encoder_activ_layer1)\n",
    "encoder_norm_layer2 = tensorflow.keras.layers.BatchNormalization(name=\"encoder_norm_2\")(encoder_conv_layer2)\n",
    "encoder_activ_layer2 = tensorflow.keras.layers.LeakyReLU(name=\"encoder_activ_layer_2\")(encoder_norm_layer2)\n",
    "\n",
    "encoder_conv_layer3 = tensorflow.keras.layers.Conv2D(filters=64, kernel_size=(3,3), padding=\"same\", strides=2, name=\"encoder_conv_3\")(encoder_activ_layer2)\n",
    "encoder_norm_layer3 = tensorflow.keras.layers.BatchNormalization(name=\"encoder_norm_3\")(encoder_conv_layer3)\n",
    "encoder_activ_layer3 = tensorflow.keras.layers.LeakyReLU(name=\"encoder_activ_layer_3\")(encoder_norm_layer3)\n",
    "\n",
    "encoder_conv_layer4 = tensorflow.keras.layers.Conv2D(filters=64, kernel_size=(3,3), padding=\"same\", strides=2, name=\"encoder_conv_4\")(encoder_activ_layer3)\n",
    "encoder_norm_layer4 = tensorflow.keras.layers.BatchNormalization(name=\"encoder_norm_4\")(encoder_conv_layer4)\n",
    "encoder_activ_layer4 = tensorflow.keras.layers.LeakyReLU(name=\"encoder_activ_layer_4\")(encoder_norm_layer4)\n",
    "\n",
    "encoder_conv_layer5 = tensorflow.keras.layers.Conv2D(filters=64, kernel_size=(3,3), padding=\"same\", strides=1, name=\"encoder_conv_5\")(encoder_activ_layer4)\n",
    "encoder_norm_layer5 = tensorflow.keras.layers.BatchNormalization(name=\"encoder_norm_5\")(encoder_conv_layer5)\n",
    "encoder_activ_layer5 = tensorflow.keras.layers.LeakyReLU(name=\"encoder_activ_layer_5\")(encoder_norm_layer5)\n",
    "\n",
    "shape_before_flatten = tensorflow.keras.backend.int_shape(encoder_activ_layer5)[1:]\n",
    "encoder_flatten = tensorflow.keras.layers.Flatten()(encoder_activ_layer5)\n",
    "\n",
    "encoder_mu = tensorflow.keras.layers.Dense(units=latent_space_dim, name=\"encoder_mu\")(encoder_flatten)\n",
    "encoder_log_variance = tensorflow.keras.layers.Dense(units=latent_space_dim, name=\"encoder_log_variance\")(encoder_flatten)\n",
    "\n",
    "encoder_mu_log_variance_model = tensorflow.keras.models.Model(x, (encoder_mu, encoder_log_variance), name=\"encoder_mu_log_variance_model\")\n",
    "\n",
    "def sampling(mu_log_variance):\n",
    "    mu, log_variance = mu_log_variance\n",
    "    epsilon = tensorflow.keras.backend.random_normal(shape=tensorflow.keras.backend.shape(mu), mean=0.0, stddev=1.0)\n",
    "    random_sample = mu + tensorflow.keras.backend.exp(log_variance/2) * epsilon\n",
    "    return random_sample\n",
    "\n",
    "encoder_output = tensorflow.keras.layers.Lambda(sampling, name=\"encoder_output\")([encoder_mu, encoder_log_variance])\n",
    "\n",
    "encoder = tensorflow.keras.models.Model(x, encoder_output, name=\"encoder_model\")\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wY-qYSYblrFs"
   },
   "source": [
    "## Building the Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 629
    },
    "colab_type": "code",
    "gradient": {},
    "id": "6J4TtB1kj5we",
    "outputId": "93add8f9-3c1d-4a89-f6a0-7f9d090191b1"
   },
   "outputs": [],
   "source": [
    "decoder_input = tensorflow.keras.layers.Input(shape=(latent_space_dim), name=\"decoder_input\")\n",
    "decoder_dense_layer1 = tensorflow.keras.layers.Dense(units=numpy.prod(shape_before_flatten), name=\"decoder_dense_1\")(decoder_input)\n",
    "decoder_reshape = tensorflow.keras.layers.Reshape(target_shape=shape_before_flatten)(decoder_dense_layer1)\n",
    "\n",
    "decoder_conv_tran_layer1 = tensorflow.keras.layers.Conv2DTranspose(filters=64, kernel_size=(3, 3), padding=\"same\", strides=1, name=\"decoder_conv_tran_1\")(decoder_reshape)\n",
    "decoder_norm_layer1 = tensorflow.keras.layers.BatchNormalization(name=\"decoder_norm_1\")(decoder_conv_tran_layer1)\n",
    "decoder_activ_layer1 = tensorflow.keras.layers.LeakyReLU(name=\"decoder_leakyrelu_1\")(decoder_norm_layer1)\n",
    "\n",
    "decoder_conv_tran_layer2 = tensorflow.keras.layers.Conv2DTranspose(filters=64, kernel_size=(3, 3), padding=\"same\", strides=2, name=\"decoder_conv_tran_2\")(decoder_activ_layer1)\n",
    "decoder_norm_layer2 = tensorflow.keras.layers.BatchNormalization(name=\"decoder_norm_2\")(decoder_conv_tran_layer2)\n",
    "decoder_activ_layer2 = tensorflow.keras.layers.LeakyReLU(name=\"decoder_leakyrelu_2\")(decoder_norm_layer2)\n",
    "\n",
    "decoder_conv_tran_layer3 = tensorflow.keras.layers.Conv2DTranspose(filters=64, kernel_size=(3, 3), padding=\"same\", strides=2, name=\"decoder_conv_tran_3\")(decoder_activ_layer2)\n",
    "decoder_norm_layer3 = tensorflow.keras.layers.BatchNormalization(name=\"decoder_norm_3\")(decoder_conv_tran_layer3)\n",
    "decoder_activ_layer3 = tensorflow.keras.layers.LeakyReLU(name=\"decoder_leakyrelu_3\")(decoder_norm_layer3)\n",
    "\n",
    "decoder_conv_tran_layer4 = tensorflow.keras.layers.Conv2DTranspose(filters=1, kernel_size=(3, 3), padding=\"same\", strides=1, name=\"decoder_conv_tran_4\")(decoder_activ_layer3)\n",
    "decoder_output = tensorflow.keras.layers.LeakyReLU(name=\"decoder_output\")(decoder_conv_tran_layer4 )\n",
    "\n",
    "decoder = tensorflow.keras.models.Model(decoder_input, decoder_output, name=\"decoder_model\")\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0Inw7qEUlkEc"
   },
   "source": [
    "## Building the VAE out of the Encoder and the Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "gradient": {},
    "id": "ufkT79GPkgpH",
    "outputId": "67bc5c68-2269-475a-cb9c-2134e386585d"
   },
   "outputs": [],
   "source": [
    "vae_input = tensorflow.keras.layers.Input(shape=(img_size, img_size, num_channels), name=\"VAE_input\")\n",
    "vae_encoder_output = encoder(vae_input)\n",
    "vae_decoder_output = decoder(vae_encoder_output)\n",
    "vae = tensorflow.keras.models.Model(vae_input, vae_decoder_output, name=\"VAE\")\n",
    "vae.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yb3RzAwYlgjl"
   },
   "source": [
    "## Loss Function & Model Compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "gradient": {},
    "id": "ejtyOLYPkm6c"
   },
   "outputs": [],
   "source": [
    "def loss_func(encoder_mu, encoder_log_variance):\n",
    "    def vae_reconstruction_loss(y_true, y_predict):\n",
    "        reconstruction_loss_factor = 1000\n",
    "        reconstruction_loss = tensorflow.keras.backend.mean(tensorflow.keras.backend.square(y_true-y_predict), axis=[1, 2, 3])\n",
    "        return reconstruction_loss_factor * reconstruction_loss\n",
    "\n",
    "    def vae_kl_loss(encoder_mu, encoder_log_variance):\n",
    "        kl_loss = -0.5 * tensorflow.keras.backend.sum(1.0 + encoder_log_variance - tensorflow.keras.backend.square(encoder_mu) - tensorflow.keras.backend.exp(encoder_log_variance), axis=1)\n",
    "        return kl_loss\n",
    "\n",
    "    def vae_kl_loss_metric(y_true, y_predict):\n",
    "        kl_loss = -0.5 * tensorflow.keras.backend.sum(1.0 + encoder_log_variance - tensorflow.keras.backend.square(encoder_mu) - tensorflow.keras.backend.exp(encoder_log_variance), axis=1)\n",
    "        return kl_loss\n",
    "\n",
    "    def vae_loss(y_true, y_predict):\n",
    "        reconstruction_loss = vae_reconstruction_loss(y_true, y_predict)\n",
    "        kl_loss = vae_kl_loss(y_true, y_predict)\n",
    "\n",
    "        loss = reconstruction_loss + kl_loss\n",
    "        return loss\n",
    "\n",
    "    return vae_loss\n",
    "\n",
    "vae.compile(optimizer=tensorflow.keras.optimizers.Adam(lr=0.0005), loss=loss_func(encoder_mu, encoder_log_variance))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gURyli7_ldAv"
   },
   "source": [
    "## Loading the Data and Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "gradient": {},
    "id": "uuxiRs1Ukrvb",
    "outputId": "61b72af7-b3db-4bfe-ef94-45ebd71bd5e4"
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tensorflow.keras.datasets.mnist.load_data()\n",
    "x_train = x_train.astype(\"float32\") / 255.0\n",
    "x_test = x_test.astype(\"float32\") / 255.0\n",
    "\n",
    "x_train = numpy.reshape(x_train, newshape=(x_train.shape[0], x_train.shape[1], x_train.shape[2], 1))\n",
    "x_test = numpy.reshape(x_test, newshape=(x_test.shape[0], x_train.shape[1], x_train.shape[2], 1))\n",
    "\n",
    "vae.fit(x_train, x_train, epochs=20, batch_size=32, shuffle=True, validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0L-lAAmolar9"
   },
   "source": [
    "## Saving the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "gradient": {},
    "id": "v-YedmB3kxM8"
   },
   "outputs": [],
   "source": [
    "encoder.save(\"VAE_encoder.h5\")\n",
    "decoder.save(\"VAE_decoder.h5\")\n",
    "vae.save(\"VAE.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b_R3UcEGlY8B"
   },
   "source": [
    "## Testing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "gradient": {},
    "id": "80jO7_Jcky1g"
   },
   "outputs": [],
   "source": [
    "encoder = tensorflow.keras.models.load_model(\"VAE_encoder.h5\", compile=False)\n",
    "decoder = tensorflow.keras.models.load_model(\"VAE_decoder.h5\", compile=False)\n",
    "\n",
    "# Preparing MNIST Dataset\n",
    "(x_train, y_train), (x_test, y_test) = tensorflow.keras.datasets.mnist.load_data()\n",
    "x_test = x_test.astype(\"float32\") / 255.0\n",
    "\n",
    "x_test = numpy.reshape(x_test, newshape=(x_test.shape[0], x_train.shape[1], x_train.shape[2], 1))\n",
    "\n",
    "encoded_data = encoder.predict(x_test)\n",
    "decoded_data = decoder.predict(encoded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
